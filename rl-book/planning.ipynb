{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Planning\n",
    "\n",
    "Planning is a method of simulating a sequence of actions in an environment model before actually taking an action in the real environment.\n",
    "\n",
    "Concepts covered:\n",
    "1. Cross entropy method\n",
    "2. Monte Carlo tree search\n",
    "3. Probabilistic ensembles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Entropy Method\n",
    "\n",
    "The Cross Entroy Method (CEM) is a gradient-free optimization method commonly used for planning in model-based reinforcement learning.\n",
    "\n",
    "CEM Algorithm\n",
    "1. Create a Gaussian distribution $N(\\mu,\\sigma)$ that describes the weights $\\theta$ of the neural network.\n",
    "2. Sample $N$ batch samples of $\\theta$ from the Gaussian.\n",
    "3. Evaluate all $N$ samples of $\\theta$ using the value function, e.g. running trials.\n",
    "4. Select the top % of the samples of $\\theta$ and compute the new $\\mu$ and $\\sigma$ to parameterise the new Gaussian distribution.\n",
    "5. Repeat steps 1-4 until convergence."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "import gym\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# RL Gym\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Initialisation\n",
    "n = 10  # number of candidate policies\n",
    "top_k = 0.40  # top % selected for next iteration\n",
    "mean = np.zeros((5,2))  # shape = (n_parameters, n_actions)\n",
    "stddev = np.ones((5,2))  # shape = (n_parameters, n_actions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_batch_weights(mean, stddev, n):\n",
    "    mvn = tfd.MultivariateNormalDiag(\n",
    "        loc=mean,\n",
    "        scale_diag=stddev)\n",
    "    return mvn.sample(n).numpy()\n",
    "\n",
    "def policy(obs, weights):\n",
    "    return np.argmax(obs @ weights[:4,:] + weights[4])\n",
    "\n",
    "def run_trial(weights, render=False):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    reward = 0\n",
    "    while not done:\n",
    "        a = policy(obs, weights)\n",
    "        obs, r, done, _ = env.step(a)\n",
    "        reward += r\n",
    "        if render:\n",
    "            env.render()\n",
    "    return reward\n",
    "\n",
    "def get_new_mean_stddev(rewards, batch_weights):\n",
    "    idx = np.argsort(rewards)[::-1][:int(n*top_k)]\n",
    "    mean = np.mean(batch_weights[idx], axis=0)\n",
    "    stddev = np.sqrt(np.var(batch_weights[idx], axis=0))\n",
    "    return mean, stddev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.0, 10.0, 9.0, 15.0, 11.0, 17.0, 17.0, 8.0, 9.0, 46.0]\n",
      "[13.0, 99.0, 8.0, 25.0, 10.0, 45.0, 21.0, 18.0, 35.0, 35.0]\n",
      "[43.0, 66.0, 26.0, 43.0, 48.0, 51.0, 59.0, 50.0, 126.0, 40.0]\n",
      "[37.0, 52.0, 38.0, 75.0, 72.0, 55.0, 156.0, 29.0, 83.0, 210.0]\n",
      "[66.0, 46.0, 47.0, 110.0, 63.0, 45.0, 117.0, 25.0, 75.0, 67.0]\n",
      "[141.0, 53.0, 126.0, 73.0, 118.0, 60.0, 82.0, 141.0, 164.0, 93.0]\n",
      "[115.0, 117.0, 99.0, 126.0, 94.0, 198.0, 102.0, 208.0, 76.0, 136.0]\n",
      "[146.0, 116.0, 206.0, 145.0, 103.0, 82.0, 132.0, 108.0, 96.0, 152.0]\n",
      "[124.0, 135.0, 100.0, 123.0, 98.0, 182.0, 134.0, 166.0, 111.0, 121.0]\n",
      "[146.0, 112.0, 94.0, 111.0, 144.0, 154.0, 100.0, 113.0, 127.0, 102.0]\n",
      "[180.0, 105.0, 122.0, 107.0, 94.0, 165.0, 132.0, 97.0, 80.0, 188.0]\n",
      "[170.0, 123.0, 135.0, 136.0, 99.0, 161.0, 123.0, 147.0, 135.0, 104.0]\n",
      "[138.0, 98.0, 118.0, 103.0, 190.0, 96.0, 203.0, 106.0, 118.0, 105.0]\n",
      "[122.0, 100.0, 108.0, 120.0, 191.0, 178.0, 145.0, 119.0, 94.0, 104.0]\n",
      "[94.0, 134.0, 116.0, 143.0, 113.0, 163.0, 154.0, 207.0, 145.0, 147.0]\n",
      "[215.0, 140.0, 150.0, 175.0, 170.0, 188.0, 106.0, 175.0, 181.0, 106.0]\n",
      "[128.0, 119.0, 172.0, 146.0, 142.0, 95.0, 96.0, 151.0, 132.0, 126.0]\n",
      "[114.0, 125.0, 116.0, 132.0, 131.0, 100.0, 139.0, 150.0, 137.0, 123.0]\n",
      "[147.0, 162.0, 153.0, 134.0, 177.0, 138.0, 162.0, 124.0, 157.0, 103.0]\n",
      "[164.0, 109.0, 137.0, 198.0, 111.0, 158.0, 213.0, 115.0, 108.0, 115.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    batch_weights = get_batch_weights(mean, stddev, n)\n",
    "    rewards = [run_trial(weights) for weights in batch_weights]\n",
    "    mean, stddev = get_new_mean_stddev(rewards, batch_weights)\n",
    "    print(rewards)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[-0.69079407,  0.4850589 ],\n        [ 0.10470737,  0.22073966],\n        [-0.6316004 , -0.33848435],\n        [-0.92844697,  1.94632246],\n        [ 0.42116319,  0.45191136]]),\n array([[0.0044287 , 0.00021798],\n        [0.0028252 , 0.00163548],\n        [0.01741926, 0.00442157],\n        [0.00040444, 0.00117998],\n        [0.0003756 , 0.00224895]]))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, stddev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "best_weights = get_batch_weights(mean, stddev, 1)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "97.0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_trial(best_weights, render=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Monte Carlo Tree Search\n",
    "\n",
    "Upcoming"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Probabilistic Ensembles\n",
    "\n",
    "Upcoming"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}